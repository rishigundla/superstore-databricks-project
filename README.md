# ğŸš€ Databricks ETL Project â€” Medallion Architecture | Unity Catalog | Delta Lake | BI Dashboard

> **Beginner-to-Intermediate End-to-End Data Engineering Project**  
> ğŸ§  *Azure Databricks | PySpark | SQL | Delta Optimization | BI Dashboard*

This project demonstrates how I built a **complete ETL pipeline** on Databricks â€” starting from raw data ingestion to delivering interactive business insights through BI dashboards.  
The implementation leverages **Medallion Architecture**, **Unity Catalog** for governance, **Delta Lake** for reliability and performance, and **Databricks BI Dashboard** for visualization.

ğŸ“º **Reference Tutorial:** [Watch the full walkthrough](https://youtu.be/hUTDVTuZO60?si=yoJuF7wgkG3BTLUv)

---

## ğŸª„ Project Highlights

- ğŸ“¥ Built a scalable **ETL pipeline** using **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)  
- ğŸ§­ Implemented **Unity Catalog** for governance, security, and data lineage  
- âš¡ Leveraged **Delta Lake features**: Time Travel, Cloning, Vacuum, Table Utilities  
- ğŸ§° Used both traditional and modern **Delta optimization techniques**  
- ğŸ§¾ Applied **Table Utility Commands** to manage tables effectively  
- ğŸ“Š Designed a **Databricks BI Dashboard** to visualize KPIs and trends  
- ğŸ” Implemented **Row-Level & Column-Level Security** for controlled data access

---

## ğŸ§­ Architecture Overview

![Medallion Architecture Diagram](./assets/medallion_architecture_diagram.png)

1. **Data Ingestion (Bronze)** â€” Raw Superstore dataset ingested from ADLS Gen2  
2. **Data Cleaning (Silver)** â€” Data validation, deduplication & formatting  
3. **Data Transformation (Gold)** â€” Business rules, aggregations, hierarchies & KPIs  
4. **Visualization** â€” Dashboard creation directly in Databricks

---

## ğŸ§° Tech Stack

| Category                  | Tools / Tech Used                                |
|---------------------------|--------------------------------------------------|
| Data Platform             | Azure Databricks                                 |
| Storage                   | ADLS Gen2, Delta Tables                           |
| Governance                | Unity Catalog                                    |
| Language                  | PySpark, SQL                                     |
| Architecture              | Medallion (Bronze, Silver, Gold)                  |
| Optimization              | Delta Optimization Techniques                     |
| Visualization             | Databricks BI Dashboard                           |

---

## ğŸ§± Unity Catalog â€” Object Model

- âœ… Create Metastore  
- âœ… Create Credential  
- âœ… Create External Locations  
- âœ… Create Catalog & Schema  
- âœ… Create Delta Tables  
- ğŸ” Implement RLS/CLS for access control

---

## ğŸ§  Delta Lake Features Implemented

- Managed vs External Delta Tables  
- DML Commands (Insert, Update, Delete)  
- Vacuum with Dry Run  
- Version History & Time Travel  
- Deep vs Shallow Clone  
- Table Utility Commands  
- Checkpoints & Optimization Techniques

---

## ğŸ§° Table Utility Commands Used

- `DESCRIBE TABLE` / `DESCRIBE DETAIL` / `DESCRIBE HISTORY`  
- `OPTIMIZE` / `ZORDER BY`  
- `ALTER TABLE ... SET TBLPROPERTIES`  
- `ALTER TABLE ... SET TAGS`  
- `SHOW TBLPROPERTIES`  
- `RESTORE TABLE TO VERSION AS OF`  
- `DROP TABLE`, `VACUUM`, `CHECKPOINTS`

---

## âš¡ Optimization Techniques

### Traditional
- OPTIMIZE Command  
- ZORDER BY  
- Auto Optimize & Auto Compact  
- Caching  
- Data Skipping  
- Partitioning

### Modern
- Liquid Clustering  
- Deletion Vectors  
- Change Data Feed (CDC)  
- Schema Evolution

---

## ğŸ“Š BI Dashboard

![Dashboard Screenshot](./assets/dashboard_screenshot.png)

### Key Metrics:
- **Total Sales:** $1.81M  
- **Total Profit:** $437.37K  
- **Total Quantity Sold:** 29.96K  

### Dashboard Features:
- ğŸ“ˆ Year-over-Year Sales vs Profit Trend  
- ğŸ›ï¸ Category-wise distribution  
- ğŸŒ Region-level filter  
- ğŸ”„ Real-time insights inside Databricks

---

## ğŸ““ Project Notebooks

| Notebook | File | Description |
|----------|------|-------------|
| 01 | `01_data_ingestion_bronze.ipynb` | Ingest raw data into Bronze layer |
| 02 | `02_data_cleaning_silver.ipynb` | Data cleaning, validation, transformation |
| 03 | `03_data_transformation_gold.ipynb` | Business logic, aggregation, KPI creation |
| 04 | `04_hierarchy_creation.ipynb` | Hierarchy & dimensional modeling |

All notebooks are included in the [`notebooks/`](./notebooks) directory for reference.

---

## ğŸ›¡ï¸ Data Governance & Security

- âœ… Row-Level Security (RLS)  
- âœ… Column-Level Security (CLS)  
- ğŸª„ Data Lineage through Unity Catalog

---

## ğŸ“š Key Learnings

- Designing and implementing **Medallion Architecture** on Databricks  
- Real-world **Unity Catalog** setup and governance  
- Deep dive into **Delta Lake features**: versioning, cloning, optimization  
- Building ETL pipelines using **PySpark + SQL**  
- Dashboarding inside Databricks for fast insights  
- Applying **data governance** best practices in analytics

---

## ğŸš€ Future Enhancements

- âš¡ Automate the pipeline using Databricks Workflows  
- ğŸ“¡ Incremental & streaming ingestion  
- ğŸ“Š Integrate with Tableau / Power BI for richer visualizations  
- ğŸ§ª Add data quality checks & monitoring  
- ğŸ›¡ï¸ Implement CI/CD with Unity Catalog & GitHub Actions

---

## ğŸ‘¨â€ğŸ’» Author

**Rishikesh Gundla**  
ğŸ“Š Senior BI Engineer | ğŸ“ India  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/rishikeshgundla/)

---

â­ *If you found this project useful, give it a star to support!*  
ğŸ“ *This is part of my data engineering portfolio demonstrating real-world Databricks ETL implementation.*
